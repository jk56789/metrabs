{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 yolo4\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def download_model(model_type):\n",
    "    server_prefix = 'https://omnomnom.vision.rwth-aachen.de/data/metrabs'\n",
    "    model_zippath = tf.keras.utils.get_file(\n",
    "        origin=f'{server_prefix}/{model_type}.zip',\n",
    "        extract=True, cache_subdir='models')\n",
    "    model_path = os.path.join(os.path.dirname(model_zippath), model_type)\n",
    "    return model_path\n",
    "\n",
    "model = tf.saved_model.load(download_model('metrabs_rn18_y4'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw\n",
    "import cv2\n",
    "def loop_through_people(frame ,keypoints_with,boxes_with,check):\n",
    "\n",
    "    for person, box in zip(keypoints_with,boxes_with):\n",
    "        a,b,c,d,per = box\n",
    "        \n",
    "        \n",
    "        if per > 0.50:    \n",
    "            for xy in person:\n",
    "                cv2.circle(frame,(int(xy[0]),int(xy[1])), 3, (0,255,0),-1)\n",
    "                cv2.rectangle(frame,(int(a),int(b),int(c),int(d)),(255,0,0),2) \n",
    "                p = round(per,5)\n",
    "                cv2.putText(frame,str(p),(int(a),int(b)),1,1,(0,255,0),2,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디버깅\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "cam1=cv2.VideoCapture(\"C:/Users/Leeyourack/jookyoung/video/1.test_video/time_test1.avi\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('C:/Users/Leeyourack/jookyoung/video/2.detect_video/TEST.mp4', fourcc, 5.0, (2560, 720))\n",
    "frame=0\n",
    "df= []\n",
    "detect=[]\n",
    "while True:\n",
    "    \n",
    "    #영상 로드\n",
    "    _,img1=cam1.read()\n",
    "    _,img2=cam1.read()\n",
    "\n",
    "    '''#영상 정보\n",
    "    w = round(cam1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cam1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cam1.get(cv2.CAP_PROP_FPS)'''\n",
    "    \n",
    "\n",
    "    #이미지 분석\n",
    "    results1 = model.detect_poses(img1, skeleton='smpl_24') #예측1\n",
    "    \n",
    "    poses2d_1 = results1['poses2d'].numpy()\n",
    "    poses3d_1 = results1['poses3d'].numpy()\n",
    "    boxes_1 = results1['boxes'].numpy()\n",
    "\n",
    "    \n",
    "    #keypoints추출\n",
    "    loop_through_people(img1, poses2d_1, boxes_1,frame)\n",
    "    \n",
    "    #데이터 프레임 만들기\n",
    "    df.append([frame,'nan'])\n",
    "    for box in boxes_1:\n",
    "        a,b,c,d,per = box\n",
    "        if per > 0.50:\n",
    "            df[frame][1]=per\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #이미지 합치기\n",
    "    cv2.resize(img1,(480,640))\n",
    "    cv2.resize(img2,(480,640))\n",
    "\n",
    "    two_img=cv2.hconcat([img1,img2])\n",
    "    \n",
    "\n",
    "\n",
    "    #디버깅을 위한 이미지 식별번호\n",
    "    cv2.putText(two_img, f\"{frame}\" , (900,100), cv2.FONT_HERSHEY_SIMPLEX, 4, (0,255,0), 2)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #이미지 보여주기\n",
    "    cv2.imshow(\"TEST1\",two_img)\n",
    "\n",
    "    \n",
    "\n",
    "    #이미지 저장하기\n",
    "    cv2.imwrite('C:/Users/Leeyourack/jookyoung/image/ar1/''3d'+str(frame)+'.jpg',two_img)\n",
    "\n",
    "    #영상 저장하기\n",
    "    out.write(two_img)\n",
    "\n",
    "    \n",
    "    frame = frame + 1\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    df_frame= pd.DataFrame(df, columns = ['frame','percent'])\n",
    "    df_frame.to_csv('C:/Users/Leeyourack/jookyoung/data/debug.csv')\n",
    "\n",
    "    \n",
    "cam1.release() \n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 영상으로 만들기\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    " \n",
    "img_array = []\n",
    "\n",
    "\n",
    " \n",
    "for filename in [f\"3d{1*(x+1)}.jpg\" for x in range(1916)]:\n",
    "    img = cv2.imread(f\"C:/Users/Leeyourack/jookyoung/image/ar1/{filename}\")\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    " \n",
    " \n",
    "out = cv2.VideoWriter('C:/Users/Leeyourack/jookyoung/video/2.detect_video/test11.avi',cv2.VideoWriter_fourcc(*'DIVX'), 5, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('metrabs': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c298febc1624e7004931ab9f383ad905d2d16c4d941da8fb932c4c60d1425215"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
