{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.04152892e-03,  1.82407614e-01,  1.69835984e+02],\n",
       "       [-2.95909021e-01,  7.01168088e-01,  2.40420095e+02],\n",
       "       [-9.49469069e-04,  1.25231345e-03,  1.00000000e+00]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "before1 = np.float32([[346, 623],[915,401],[714, 155],[169,92]])\n",
    "after1 = np.float32([[196,396],[388,396],[388,267],[196,267]])\n",
    "\n",
    "M1 = cv2.getPerspectiveTransform(before1,after1)\n",
    "M1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.07120712e+01,  1.36392767e+01, -1.87081143e+03],\n",
       "       [-4.03074220e-01,  1.88963717e+00,  3.33359281e+03],\n",
       "       [ 3.16939051e-02,  2.37680673e-02,  1.00000000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before2 = np.float32([[942,709],[100,500],[197,306],[983,174]])\n",
    "after2 = np.float32([[375,90],[375,264],[304,264],[304,90]])\n",
    "\n",
    "M2 = cv2.getPerspectiveTransform(before2,after2)\n",
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.98283981e+01, -4.23554973e+01,  1.51268349e+04],\n",
       "       [-2.58291582e+01, -4.78288334e+01,  7.48401733e+03],\n",
       "       [-7.93668243e-02, -8.47342837e-02,  1.00000000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before3 = np.float32([[733,718],[203,542],[415,220],[935,131]])\n",
    "after3 = np.float32([[439,388],[294,388],[294,272],[439,272]]) \n",
    "\n",
    "M3 = cv2.getPerspectiveTransform(before3,after3)\n",
    "M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 yolo4\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def download_model(model_type):\n",
    "    server_prefix = 'https://omnomnom.vision.rwth-aachen.de/data/metrabs'\n",
    "    model_zippath = tf.keras.utils.get_file(\n",
    "        origin=f'{server_prefix}/{model_type}.zip',\n",
    "        extract=True, cache_subdir='models')\n",
    "    model_path = os.path.join(os.path.dirname(model_zippath), model_type)\n",
    "    return model_path\n",
    "\n",
    "model = tf.saved_model.load(download_model('metrabs_rn18_y4'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('C:/Users/Leeyourack/jookyoung/image/1.test_image/peo3.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.detect_poses(image, skeleton='smpl_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[434.09357, 465.93677],\n",
       "        [473.65503, 475.3583 ]],\n",
       "\n",
       "       [[323.9566 , 447.51376],\n",
       "        [325.25552, 456.21518]],\n",
       "\n",
       "       [[572.61115, 424.22998],\n",
       "        [554.3382 , 415.16852]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['poses2d'].numpy()[:,7:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame,keypoints):\n",
    "    shaped = np.squeeze(keypoints)\n",
    "    \n",
    "    for p in shaped:\n",
    "        x,y = p\n",
    "        if x > 0:\n",
    "            cv2.circle(frame,(int(x),int(y)), 4, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_people(frame ,keypoints_with):\n",
    "    for person in keypoints_with:\n",
    "        draw_keypoints(frame,person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962.94257\n",
      "653.8557\n",
      "1112.7269\n"
     ]
    }
   ],
   "source": [
    "all=pred['poses2d'].numpy()\n",
    "for i, person in enumerate(all):\n",
    "    print(person[0][0]+person[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뒷 왼쪽발 [[434.09357 465.93677]\n",
      " [323.9566  447.51376]\n",
      " [572.61115 424.22998]]\n",
      "뒷 오른쪽발 [[473.65503 475.3583 ]\n",
      " [325.25552 456.21518]\n",
      " [554.3382  415.16852]]\n",
      "앞 왼쪽발 [[421.0414  469.6874 ]\n",
      " [336.45953 452.16455]\n",
      " [567.03015 431.85123]]\n",
      "앞 오른쪽발 [[474.6752  480.8792 ]\n",
      " [343.96637 466.2968 ]\n",
      " [543.4464  421.52954]]\n",
      "꼭지 [[447.8583  475.28333]\n",
      " [340.21295 459.23068]\n",
      " [555.2383  426.69037]]\n"
     ]
    }
   ],
   "source": [
    "print('뒷 왼쪽발',pred['poses2d'].numpy()[:,7]) #뒷 왼쪽발\n",
    "print('뒷 오른쪽발',pred['poses2d'].numpy()[:,8]) #뒷 오른쪽발\n",
    "print('앞 왼쪽발',pred['poses2d'].numpy()[:,10]) # 앞 왼쪽발\n",
    "print('앞 오른쪽발',pred['poses2d'].numpy()[:,11]) # 앞 오른쪽발\n",
    "print('꼭지',pred['poses2d'].numpy()[:,10]/2+pred['poses2d'].numpy()[:,11]/2) # 꼭지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROI_image = cv2.imread('C:/Users/Leeyourack/jookyoung/image/0.ROI_image/pre_image_final.jpg')\n",
    "cv2.polylines(ROI_image,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_foot_1 = M1@(front_x_1 , front_y_1 , 1)\n",
    "            trans_foot_1 = trans_foot_1/trans_foot_1[2]\n",
    "            trans_x_1 = trans_foot_1[0]\n",
    "            trans_y_1 = trans_foot_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_list1=[]\n",
    "def mat1(M1,x,y):\n",
    "    \n",
    "    trans_1 = M1@(x,y,1)\n",
    "    trans_1 = trans_1/trans_1[2]\n",
    "    tx_1= trans_1[0]\n",
    "    ty_1 = trans_1[1]\n",
    "    trans_list1.append([tx_1,ty_1])\n",
    "    print(trans_list1)\n",
    "    \n",
    "\n",
    "trans_list2=[]\n",
    "def mat2(M2,x,y):\n",
    "    \n",
    "    trans_2 = M2@(x,y,1)\n",
    "    trans_2 = trans_2/trans_2[2]\n",
    "    tx_2= trans_2[0]\n",
    "    ty_2 = trans_2[1]\n",
    "    trans_list2.append([tx_2,ty_2])\n",
    "    \n",
    "\n",
    "trans_list3=[]\n",
    "def mat3(M3,x,y):\n",
    "    \n",
    "    trans_3 = M3@(x,y,1)\n",
    "    trans_3 = trans_3/trans_3[2]\n",
    "    tx_3= trans_3[0]\n",
    "    ty_3 = trans_3[1]\n",
    "    trans_list3.append([tx_3,ty_3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = np.array([[left_x_1,left_y_1],[right_x_1,right_y_1],[front_x_1,front_y_1]], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.04152892e-03,  1.82407614e-01,  1.69835984e+02],\n",
       "       [-2.95909021e-01,  7.01168088e-01,  2.40420095e+02],\n",
       "       [-9.49469069e-04,  1.25231345e-03,  1.00000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 None\n",
      "2 None\n",
      "3 [[-1046.749843071012, 2153.8762109717745], [-108.22700616133523, 952.563061428718], [-1046.749843071012, 2153.8762109717745], [-108.22700616133523, 952.563061428718], [-1046.749843071012, 2153.8762109717745], [-108.22700616133523, 952.563061428718], [-1046.749843071012, 2153.8762109717745], [-108.22700616133523, 952.563061428718], [-1046.749843071012, 2153.8762109717745], [-108.22700616133523, 952.563061428718], [-1046.749843071012, 2153.8762109717745], [-108.22700616133523, 952.563061428718], [-1046.749843071012, 2153.8762109717745], [-108.22700616133523, 952.563061428718]]\n"
     ]
    }
   ],
   "source": [
    "print('1',mat2(M2,10,10))\n",
    "print('2',mat2(M2,10,100))\n",
    "print('3',trans_list2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#카메라 3대  원하는 영역에서 검출된 발만 mapping\n",
    "#방향\n",
    "\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "\n",
    "ROI_image = cv2.imread('C:/Users/Leeyourack/jookyoung/image/0.ROI_image/pre_image_final.jpg')\n",
    "#ROI_image2 = cv2.imread('C:/Users/Leeyourack/jookyoung/image/0.ROI_image/pre_image_final.jpg')\n",
    "\n",
    "def writeVideo():\n",
    "    global ROI_image\n",
    "    global ROI_image2\n",
    "    \n",
    "    #현재시간 가져오기\n",
    "    currentTime = datetime.datetime.now()\n",
    "    \n",
    "    #RTSP를 불러오는 곳\n",
    "    video_capture1 = cv2.VideoCapture(\"C:/Users/Leeyourack/jookyoung/video/1.test_video/new_test1.avi\")\n",
    "    video_capture2 = cv2.VideoCapture(\"C:/Users/Leeyourack/jookyoung/video/1.test_video/new_test2.avi\")\n",
    "    video_capture3 = cv2.VideoCapture(\"C:/Users/Leeyourack/jookyoung/video/1.test_video/new_test3.avi\")\n",
    "    \n",
    "\n",
    "    # 웹캠 설정\n",
    "    video_capture1.set(3, 800)  # 영상 가로길이 설정\n",
    "    video_capture1.set(4, 600)  # 영상 세로길이 설정\n",
    "    # 웹캠 설정\n",
    "    video_capture2.set(3, 800)  # 영상 가로길이 설정\n",
    "    video_capture2.set(4, 600)  # 영상 세로길이 설정\n",
    "    # 웹캠 설정\n",
    "    video_capture3.set(3, 800)  # 영상 가로길이 설정\n",
    "    video_capture3.set(4, 600)  # 영상 세로길이 설정\n",
    "    \n",
    "    # 가로 길이 가져오기\n",
    "    streaming_window_width = int(video_capture1.get(3))\n",
    "    # 세로 길이 가져오기\n",
    "    streaming_window_height = int(video_capture1.get(4))  \n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    #현재 시간을 '년도 달 일 시간 분 초'로 가져와서 문자열로 생성\n",
    "    fileName = str(currentTime.strftime('%Y %m %d %H %M %S'))\n",
    "\n",
    "    #파일 저장하기 위한 변수 선언\n",
    "    path1 = 'C:/Users/Leeyourack/jookyoung/video/2.detect_video/test1.avi'\n",
    "    #파일 저장하기 위한 변수 선언\n",
    "    path2 = 'C:/Users/Leeyourack/jookyoung/video/2.detect_video/test2.avi'\n",
    "    #파일 저장하기 위한 변수 선언\n",
    "    path3 = 'C:/Users/Leeyourack/jookyoung/video/2.detect_video/test3.avi'\n",
    "    #파일 저장하기 위한 변수 선언\n",
    "    path4 = 'C:/Users/Leeyourack/jookyoung/video/2.detect_video/test4-2.avi'\n",
    "    #파일 저장하기 위한 변수 선언\n",
    "    path5 = 'C:/Users/Leeyourack/jookyoung/video/2.detect_video/test5.avi'\n",
    "    \n",
    "    # DIVX 코덱 적용 # 코덱 종류 # DIVX, XVID, MJPG, X264, WMV1, WMV2\n",
    "    # 무료 라이선스의 이점이 있는 XVID를 사용\n",
    "    fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
    "    fps = 20\n",
    "    # 비디오 저장\n",
    "    # cv2.VideoWriter(저장 위치, 코덱, 프레임, (가로, 세로))\n",
    "    out1 = cv2.VideoWriter(path1, fourcc, fps, (streaming_window_width, streaming_window_height))\n",
    "    out2 = cv2.VideoWriter(path2, fourcc, fps, (streaming_window_width, streaming_window_height))\n",
    "    out3 = cv2.VideoWriter(path3, fourcc, fps, (streaming_window_width, streaming_window_height))\n",
    "    out4 = cv2.VideoWriter(path4, fourcc, fps, (1280, 540))\n",
    "    out5 = cv2.VideoWriter(path5, fourcc, fps, (640, 480))\n",
    "\n",
    "    while True:\n",
    "        ROI_image2 = cv2.imread('C:/Users/Leeyourack/jookyoung/image/0.ROI_image/pre_image_final.jpg')\n",
    "        ret1, frame1 = video_capture1.read()\n",
    "        ret2, frame2 = video_capture2.read()\n",
    "        ret3, frame3 = video_capture3.read()\n",
    "        \n",
    "        img1 = frame1.copy()\n",
    "        img2 = frame2.copy()\n",
    "        img3 = frame3.copy()\n",
    "\n",
    "        results1 = model.detect_poses(img1, skeleton='smpl_24')\n",
    "        keypoints_with1 = results1['poses2d'].numpy()\n",
    "        results2 = model.detect_poses(img2, skeleton='smpl_24')\n",
    "        keypoints_with2 = results2['poses2d'].numpy()\n",
    "        results3 = model.detect_poses(img3, skeleton='smpl_24')\n",
    "        keypoints_with3 = results3['poses2d'].numpy()\n",
    "\n",
    "\n",
    "        '''print('뒷 왼쪽발',pred['poses2d'].numpy()[:,7]) #뒷 왼쪽발\n",
    "        print('뒷 오른쪽발',pred['poses2d'].numpy()[:,8]) #뒷 오른쪽발\n",
    "        print('앞 왼쪽발',pred['poses2d'].numpy()[:,10]) # 앞 왼쪽발\n",
    "        print('앞 오른쪽발',pred['poses2d'].numpy()[:,11]) # 앞 오른쪽발\n",
    "        print('꼭지',pred['poses2d'].numpy()[:,10]/2+pred['poses2d'].numpy()[:,11]/2) # 꼭지'''\n",
    "\n",
    "        loop_through_people(frame1, keypoints_with1) \n",
    "        camera_1 = results1['poses2d'].numpy()\n",
    "       \n",
    "\n",
    "        loop_through_people(frame2, keypoints_with2)\n",
    "        camera_2 = results2['poses2d'].numpy()\n",
    "        \n",
    "        loop_through_people(frame3, keypoints_with3)\n",
    "        camera_3 = results3['poses2d'].numpy()\n",
    "        \n",
    "        \n",
    "        poly_list_1 = [(346, 623), (915,401), (714, 155), (169,92)]\n",
    "        poly_1 = Polygon(poly_list_1)\n",
    "        for a,person1  in enumerate(camera_1):\n",
    "            left_x_1 = person1[7][0]\n",
    "            left_y_1 = person1[7][1]\n",
    "            right_x_1 = person1[8][0]\n",
    "            right_y_1 = person1[8][1]\n",
    "            front_x_1 = person1[10][0]/2 + person1[11][0]/2\n",
    "            front_y_1 = person1[10][1]/2 + person1[11][1]/2\n",
    "\n",
    "\n",
    "            trans_foot_1 = M1@(front_x_1 , front_y_1 , 1)\n",
    "            trans_foot_1 = trans_foot_1/trans_foot_1[2]\n",
    "            trans_x_1 = trans_foot_1[0]\n",
    "            trans_y_1 = trans_foot_1[1]\n",
    "            \n",
    "            trans_right_1 = M1@(right_x_1 , right_y_1 , 1)\n",
    "            trans_right_1 = trans_right_1/trans_right_1[2]\n",
    "            tr_x_1 = trans_right_1[0]\n",
    "            tr_y_1 = trans_right_1[1]\n",
    "\n",
    "            trans_left_1 = M1@(left_x_1 , left_y_1 , 1)\n",
    "            trans_left_1 = trans_left_1/trans_left_1[2]\n",
    "            tl_x_1 = trans_left_1[0]\n",
    "            tl_y_1 = trans_left_1[1]\n",
    "            \n",
    "           \n",
    "            if poly_1.contains(Point(front_x_1 , front_y_1)) == True:\n",
    "\n",
    "            #if xy_1[0] < 446 and xy_1[0] > 178 and xy_1[1] > 270 and xy_1[1] < 408: #before1 = np.float32([[346, 623],[915,401],[714, 155],[169,92]])\n",
    "                pts1 = np.array([[tl_x_1,tl_y_1],[tr_x_1,tr_y_1],[trans_x_1,trans_y_1]], np.int32)\n",
    "                ROI_image = cv2.circle(ROI_image,(int(trans_x_1),int(trans_y_1)), 3, (0,0,255), -1)\n",
    "                ROI_image2 = cv2.polylines(ROI_image2, [pts1], True, (0,0,255), 1 )\n",
    "                ROI_image2 = cv2.circle(ROI_image2,(int(trans_x_1),int(trans_y_1)), 2, (0,0,0), -1)\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        poly_list_2 = [(942,709), (100,500), (197,306), (983,174)]\n",
    "        poly_2 = Polygon(poly_list_2)\n",
    "        for b,person2  in enumerate(camera_2):\n",
    "            left_x_2 = person2[7][0]\n",
    "            left_y_2 = person2[7][1]\n",
    "            right_x_2 = person2[8][0]\n",
    "            right_y_2 = person2[8][1]\n",
    "            front_x_2 = person2[10][0]/2 + person2[11][0]/2\n",
    "            front_y_2 = person2[10][1]/2 + person2[11][1]/2\n",
    "\n",
    "\n",
    "            trans_foot_2 = M2@(front_x_2 , front_y_2 , 1)\n",
    "            trans_foot_2 = trans_foot_2/trans_foot_2[2]\n",
    "            trans_x_2 = trans_foot_2[0]\n",
    "            trans_y_2 = trans_foot_2[1]\n",
    "\n",
    "\n",
    "            trans_right_2 = M2@(right_x_2 , right_y_2 , 1)\n",
    "            trans_right_2 = trans_right_2/trans_right_2[2]\n",
    "            tr_x_2 = trans_right_2[0]\n",
    "            tr_y_2 = trans_right_2[1]\n",
    "\n",
    "            trans_left_2 = M2@(left_x_2 , left_y_2 , 1)\n",
    "            trans_left_2 = trans_left_2/trans_left_2[2]\n",
    "            tl_x_2 = trans_left_2[0]\n",
    "            tl_y_2 = trans_left_2[1]\n",
    "           \n",
    "            \n",
    "            if poly_2.contains(Point(front_x_2 , front_y_2)) == True:\n",
    "\n",
    "            #if xy_1[0] < 446 and xy_1[0] > 178 and xy_1[1] > 270 and xy_1[1] < 408: #before1 = np.float32([[346, 623],[915,401],[714, 155],[169,92]])\n",
    "                pts2 = np.array([[tl_x_2,tl_y_2],[tr_x_2,tr_y_2],[trans_x_2,trans_y_2]], np.int32)\n",
    "                ROI_image = cv2.circle(ROI_image,(int(trans_x_2),int(trans_y_2)), 3, (0,255,0), -1)\n",
    "                ROI_image2 = cv2.polylines(ROI_image2, [pts2], True, (0,255,0), 1 )\n",
    "                ROI_image2 = cv2.circle(ROI_image2,(int(trans_x_2),int(trans_y_2)), 2, (0,0,0), -1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        poly_list_3 = [(733,718), (203,542), (415,220), (935,131)]\n",
    "        poly_3 = Polygon(poly_list_3)\n",
    "        for c,person3  in enumerate(camera_3):\n",
    "            left_x_3 = person3[7][0]\n",
    "            left_y_3 = person3[7][1]\n",
    "            right_x_3 = person3[8][0]\n",
    "            right_y_3 = person3[8][1]\n",
    "            front_x_3 = person3[10][0]/2 + person3[11][0]/2\n",
    "            front_y_3 = person3[10][1]/2 + person3[11][1]/2\n",
    "\n",
    "\n",
    "            trans_foot_3 = M3@(front_x_3 , front_y_3 , 1)\n",
    "            trans_foot_3 = trans_foot_3/trans_foot_3[2]\n",
    "            trans_x_3 = trans_foot_3[0]\n",
    "            trans_y_3 = trans_foot_3[1]\n",
    "\n",
    "            trans_right_3 = M3@(right_x_3 , right_y_3 , 1)\n",
    "            trans_right_3 = trans_right_3/trans_right_3[2]\n",
    "            tr_x_3 = trans_right_3[0]\n",
    "            tr_y_3 = trans_right_3[1]\n",
    "\n",
    "            trans_left_3 = M3@(left_x_3 , left_y_3 , 1)\n",
    "            trans_left_3 = trans_left_3/trans_left_3[2]\n",
    "            tl_x_3 = trans_left_3[0]\n",
    "            tl_y_3 = trans_left_3[1]\n",
    "           \n",
    "            \n",
    "            if poly_3.contains(Point(front_x_3 , front_y_3)) == True:\n",
    "\n",
    "            #if xy_1[0] < 446 and xy_1[0] > 178 and xy_1[1] > 270 and xy_1[1] < 408: #before1 = np.float32([[346, 623],[915,401],[714, 155],[169,92]])\n",
    "                pts3 = np.array([[tl_x_3,tl_y_3],[tr_x_3,tr_y_3],[trans_x_3,trans_y_3]], np.int32)\n",
    "                ROI_image = cv2.circle(ROI_image,(int(trans_x_3),int(trans_y_3)), 3, (255,0,0), -1)\n",
    "                ROI_image2 = cv2.polylines(ROI_image2, [pts3], True, (255,0,0), 1)\n",
    "                ROI_image2 = cv2.circle(ROI_image2,(int(trans_x_3),int(trans_y_3)), 2, (0,0,0), -1)\n",
    "                \n",
    "\n",
    "        resize_frame1 = cv2.resize(frame1, (320, 180))\n",
    "        resize_frame2 = cv2.resize(frame2, (320, 180))\n",
    "        resize_frame3 = cv2.resize(frame3, (320, 180))\n",
    "        resize_ROI_image = cv2.resize(ROI_image, (960,540) )\n",
    "        \n",
    "\n",
    "        img_con = cv2.vconcat([resize_frame1, resize_frame2,resize_frame3])\n",
    "        img_hcon = cv2.hconcat([img_con, resize_ROI_image])\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        cv2.imshow('mapping', img_hcon)\n",
    "        cv2.imshow('vector', ROI_image2)\n",
    "        \n",
    "        \n",
    "        # 영상을 저장한다.\n",
    "        out1.write(frame1)\n",
    "        out2.write(frame2)\n",
    "        out3.write(frame3)\n",
    "        out4.write(img_hcon)\n",
    "        out5.write(ROI_image2)\n",
    "        \n",
    "        # 1ms뒤에 뒤에 코드 실행해준다.\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        #키보드 esc 누르면 종료된다.\n",
    "        if k == 27:\n",
    "            break\n",
    "    video_capture1.release()  # cap 객체 해제\n",
    "    video_capture2.release()  # cap 객체 해제\n",
    "    video_capture3.release()  # cap 객체 해제\n",
    "    out1.release()  # out 객체 해제\n",
    "    out2.release()  # out 객체 해제\n",
    "    out3.release()  # out 객체 해제\n",
    "    out4.release()  # out 객체 해제\n",
    "    out5.release()  # out 객체 해제\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    writeVideo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('metrabs': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c298febc1624e7004931ab9f383ad905d2d16c4d941da8fb932c4c60d1425215"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
